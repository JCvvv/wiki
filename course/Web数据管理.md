---
title: Web数据管理
description: 
published: true
date: 2024-02-26T09:36:03.486Z
tags: 
editor: markdown
dateCreated: 2024-02-26T09:36:03.486Z

---

# Web数据管理

## 课程介绍

### 课程考核

期末 80%

实验 20%，实验中心 504 机房，5~13周

### 参考书目

Web数据管理：概念与技术

Web数据挖掘（第二版）

数据挖掘概念与技术

现代信息检索

## 绪论

老师说所谓绪论就当讲座来听，稍微了解一下就行，由于 ppt 过于精简，笔者对于某些概念进行了一点点的扩充，看个乐就行。

### web 数据

#### WWW概述

WWW ：World Wide Web

WWW作为全球化信息空间，蕴含着具有巨大潜在价值的信息和知识。

WWW技术发展为数据管理带来了巨大的挑战和机遇。

Web将计算机网络技术和超媒体技术融合起来，在很短时间内就被各个领域的用户广泛接受，信息量呈爆炸式增长。

Web中这些海量和多样化数据不同于传统的数据模型。

#### web 数据的特点

1. 数据量大，并且仍然在不断增长

2. 存在各种类型的数据

   结构化表格、无结构化的文本、半结构化的网页、多媒体数据

3. 异构的信息

   内容相同，形式不同

4. 绝大部分信息是相连接的

   超文本：网站内部和网站之间的网页通过超链接联系

   Web有向图：网页为节点，HTML链接引用为有向边

   图结构符合幂律分布，可使用pagerank算法找到最重要的网页，或者是“垃圾”网页

5. 噪音的存在

   网页包含多个模块，对于特定任务只有一部分信息有用

   本身没有信息质量的控制 SPAM （垃圾）

6. 动态性

##### 扩展：计算广告学

计算广告学是一门正在兴起的分支学科，它涉及到大规模搜索和文本分析、信息获取、统计模型、机器学习、分类、优化以及微观经济学。

计算广告学所面临的最主要挑战是在特定语境下特定用户和相应的广告之间找到“最佳匹配”。语境可以是用户在搜索引擎中输入的查询词，也可以是用户正在读的网页，还可以是用户正在看的电影，等等。而用户相关的信息可能非常多也可能非常少。潜在广告的数量可能达到几十亿。因此，取决于对“最佳匹配”的定义，面临的挑战可能导致在复杂约束条件下的大规模优化和搜索问题。

##### 重点：各种类型的数据

- 半结构化或无结构化
- 非规范化，Web的开放性和用户的随意性使得信息资源的质量无法得到保证，其中可能包含一些各种各样的内容及自定义词汇等格式自由的数据
- 数据格式随意，机器难以自动处理

### web 数据管理

定义：在Web环境下，对复杂信息的有效组织与集成，方便而准确的信息，查询、集成、发布（不要记）

### web数据管理的内容

#### Web数据获取

通过机器学习发现Web上的信息结构或模式

数据抽取方法：全自动，半自动，手动

**全自动**：使用爬虫软件或者抓取工具自动访问网页，通过预定义的规则或模式匹配来提取数据。例如用Python的BeautifulSoup库或Scrapy框架来自动抓取新闻网站上的文章标题和内容。

**半自动**：结合自动化工具和人工审核，自动化工具负责初步抽取数据，人工审核则用于确保数据的准确性和完整性。例如使用自动化工具提取电商网站上的产品信息，然后人工检查和修正抽取结果中的错误或遗漏。

**手动抽取**：直接通过人工操作，从网页中复制所需的数据并粘贴到适当的存储位置。例如从一个小型的、结构不规范的网站上，手动复制联系信息或者价格列表。

#### Web数据管理中的数据组织

研究Web信息的特点，找出适合Web信息的合理组织模式

半结构化数据模式：XML，JSON，CSV

信息检索数据结构：非关系型数据库，倒排表

**倒排表**：倒排表（Inverted Index）是一种索引数据结构，用于存储单词在文档中出现的位置。它是搜索引擎的核心组件，使得根据关键词快速检索文档成为可能。在倒排表中，每个单词关联一个列表，列表中包含了该单词出现在哪些文档中以及在每个文档中的位置。这种结构便于根据关键词快速定位到包含这些关键词的文档，从而提高检索效率。

#### Web上的信息集成

Web上的信息集成是指将来自不同网站或数据源的信息整合成一个统一的、对用户友好的视图。这是Web数据管理中的一个关键挑战，尤其是在信息碎片化严重的互联网环境中。信息集成的目标是提供一个综合视图，使用户能够方便地访问和比较来自不同来源的相关信息。

例如，在旅行预订领域，一个信息集成的网站可以从多个航空公司和酒店的网站收集数据，然后在一个页面上展示所有的航班和住宿选项，让用户能够轻松比较不同的选择并做出决策。在求职网站中，信息集成可以将来自不同公司和招聘平台的职位信息汇总在一起，帮助求职者更有效地搜索和申请工作。

#### Web查询

Web查询是指在Web环境下根据用户需求检索信息的过程。它能够根据更丰富的语义信息在有效的数据组织模式下找出更准确的信息。这种查询不同于传统的模糊查询，它可以精确地定位信息的位置，提高检索的准确性和相关性。

##### 扩展：基于内容的图像查询

基于内容的图像查询（Content-Based Image Retrieval, CBIR）是一种根据图像的视觉特征如颜色、形状和纹理进行搜索的技术。这种查询方法不依赖于图像的元数据或描述文字，而是直接分析图像的内容，使得用户能够通过提供一个样例图像或指定某些视觉特征来检索相似的图像。

##### 扩展：语义查询

语义查询是一种基于对图像内容的深层次理解和解释进行检索的方法。例如，在进行“高兴的梁朝伟”的语义查询时，系统不仅需要识别出图像中的人物是梁朝伟，还需要理解其表情或情绪是高兴的。这种查询方式依赖于图像语义分析和自然语言处理技术，使得用户可以使用更接近自然语言的方式来进行图像检索。

#### Web信息发布

用户画像，信息推送、推荐（老师说以后有时间再讲）

**用户画像**：通过收集和分析用户的行为数据、偏好和兴趣点，构建用户的画像。这有助于理解用户的需求和特征，为其提供更个性化的服务。

**信息推送**：根据用户画像和实时的上下文信息，主动向用户推送他们可能感兴趣的内容。这种推送可以是新闻、广告、通知等，旨在提高用户的参与度和满意度。

**推荐系统**：利用机器学习和数据挖掘技术，分析用户的历史行为和偏好，预测他们可能感兴趣的新内容，并将其推荐给用户。推荐系统在电商、视频、音乐和社交网络等领域有广泛的应用。

### web 数据管理的基础

#### 数据获得

**爬虫**：爬虫是用于自动抽取Web数据的程序。它可以访问网页，解析HTML内容，提取出有用的信息，如文本、链接、图片等，并将这些信息存储起来供进一步处理。

**Web结构**：Web结构数据主要指的是网页之间的超链接关系。这种关系可以用图数据结构来表示，其中节点代表网页，边代表超链接。通过分析Web结构，可以了解网站的组织方式和页面之间的关联。

**Web内容**：Web内容是指网页上的实际信息，包括文本、图片、视频等。这些内容是用户最直接感兴趣的数据，也是Web数据获取的主要目标。

**Web使用**：Web使用数据是指用户与网站交互的日志信息，如点击、浏览、搜索等行为记录。这些数据对于理解用户行为和优化网站设计非常重要。

#### 数据预处理

数据筛选, 清洗

- **数据筛选**：根据分析目标和需求，从大量数据中筛选出相关的数据子集。
- **数据清洗**：处理缺失值、异常值和重复数据，纠正数据中的错误和不一致。

应用数据

- **应用数据合并**：将来自不同源或不同格式的数据合并成一个统一的数据集。
- **组织存储**：根据数据的特点和使用需求，选择合适的数据结构和存储方式。
- **检索**：建立索引和查询机制，以便快速检索和访问数据。
- **可视化**：通过图表、图像等形式直观展示数据，帮助理解数据特征和分布。

特征提取：从原始数据中提取有用的信息作为特征，用于后续的分析和模型构建。

- **文本特征**：如词频、TF-IDF、词嵌入等。
- **图像特征**：如颜色直方图、SIFT、HOG等。
- **实体特征**：根据实体的属性和关系提取特征。

#### 数据变换

数据变换是数据预处理的重要步骤，旨在将数据转换成更适合分析和建模的形式。

1. **降维**：减少数据的维度，去除冗余和无关特征，提高计算效率，同时尽量保留数据的重要信息。常用的降维方法包括主成分分析（PCA）、线性判别分析（LDA）等。

2. **空间转换**：将数据从原始空间转换到新的特征空间，以便更好地表示数据的结构和关系。这种转换通常基于某种数学模型或算法。

3. **数据矩阵奇异值分解（SVD）**：SVD是一种常用的矩阵分解技术，可以用于降维、数据压缩和噪声过滤。在信息检索和推荐系统中有广泛应用。

4. **文本潜在语义分析（LSA）**：LSA是一种基于SVD的文本分析技术，通过提取文本数据的潜在语义结构，发现词汇之间的隐含关系。

5. **语义空间转换**：将词汇或文本从原始的文本空间转换到语义空间，以便更好地捕捉语言的含义和语境。常用的方法包括词嵌入（Word Embedding）技术，如Word2Vec、GloVe等。

通过这些数据变换方法，可以有效地处理高维度、稀疏性和非线性等问题，提高数据分析和机器学习模型的性能。

#### 数据挖掘与机器学习

##### 数据挖掘（Data Mining）

数据挖掘是从大量的、不完全的、有噪声的、模糊的、随机的实际应用数据中提取隐含的、人们事先不知道的、但又是潜在有用的信息和知识的过程。数据挖掘任务可以分为两类：

1. **预测任务**：根据其他属性的值预测特定属性的值。例如，通过分析房产的面积、位置、装修等属性，预测房产的销售情况。
2. **描述任务**：概括数据中潜在联系的模式。包括监督学习的分类任务、无监督学习的聚类任务、关联规则和序列模式的挖掘等。

##### 机器学习（Machine Learning, ML）

机器学习是人工智能的核心，是一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。机器学习的目标是从有限的观察数据（样例）中通过算法学习出一般规律，学习一个预测模型，并利用这些规律对未知数据进行预测。机器学习的主要应用领域包括专家系统、认知模拟、规划和问题求解、数据挖掘、网络信息服务、图像识别、故障诊断、自然语言理解、机器人和博弈等。

##### Web数据挖掘

Web数据挖掘是一项综合性技术，包括以下几个方面：

1. **Web结构挖掘**：从表层Web结构的超链接中寻找知识。
2. **Web内容挖掘**：从网页内容中抽取有用的信息和知识。
3. **Web使用挖掘**：从记录每位用户点击情况的日志中挖掘用户访问模式。

数据挖掘常用的方法大多来自于机器学习这门学科，应用领域包括电信、银行、百货公司、超市、保险、信用卡、电子商务、税务部门、警察机关、医学等。

#### 知识发现

知识发现是指用数据库管理系统来存储数据，并使用机器学习的方法来分析这些数据，从而挖掘出大量数据背后隐藏的知识。这一过程称为数据库中的知识发现。

##### KDD过程

1. **实体（Entity）**：指的是具体的事物或概念，如人、地点、组织等。
2. **属性（Property）**：描述实体特征的信息，如人的年龄、地点的位置等。
3. **关系（Relation）**：表示实体之间的联系，如“属于”、“位于”等。

知识可以以形式化、简洁的方式表示，通常使用三元组（triple）的形式，即（实体，关系，实体/属性）。大量的三元组构成的知识库就成为了一个庞大的知识图。

##### 知识图谱构建

1. **命名实体识别（Named Entity Recognition, NER）**：识别文本中具有特定意义的实体，主要包括人名、地名、机构名等。
2. **实体链指（Entity Linking）**：将文档中的实体名字链接到知识库中特定的实体上。这涉及到实体识别和实体消歧两个经典问题。
3. **关系抽取（Relation Extraction）**：将文档中的实体关系抽取出来，主要涉及到词性标注、语法分析和依存关系树等技术。

##### 知识图谱应用

知识图谱在自动推理、问答系统等领域有广泛的应用。传统的语义解析方法将自然语言转化为一系列形式化的逻辑形式，而知识表示学习的方法则把知识库问答看做一个语义匹配过程，通过表示学习知识库以及用户问题的语义表示，得到低维空间的数值向量，实现问题和答案的向量匹配，进而计算问题-答案的得分，选择最优的候选答案。